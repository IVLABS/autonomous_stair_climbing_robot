{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torchvision as vision\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "class stairdata(Dataset):\n",
    "    def __init__(self, datafolder, transforms):\n",
    "        super(stairdata, self).__init__()\n",
    "        self.images = list(map(lambda x: datafolder+x, os.listdir(datafolder)))\n",
    "        self.transform = transforms\n",
    "    \n",
    "    def get_label(string): \n",
    "        return int((string.split('.')[-2]).split('_')[-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.datafolder))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx])\n",
    "        image = self.transform(image)\n",
    "        return (image, self.get_label(self.images[idx]))\n",
    "\n",
    "\n",
    "class trainer(object):\n",
    "    def __init__(self, net,  loss_function, train_folder, val_folder, batch_size=100, optimizer=T.optim.Adam, lr=0.001, start_epoch= 1, nb_epochs=10,\n",
    "                    save_dir='model/'):\n",
    "        self.net = net\n",
    "        self.batch_size = batch_size\n",
    "        self.optimizer = optimizer(self.net.parameters(), lr=lr)\n",
    "        self.loss_function = loss_function\n",
    "        self.save_dir = save_dir\n",
    "        self.train_folder = train_folder\n",
    "        self.val_folder = val_folder\n",
    "        self.running_loss_train = list()\n",
    "        self.running_loss_val = list()\n",
    "        self.accuracy = list()\n",
    "\n",
    "    def fit(self, nb_epochs, start_epoch=1, print_after=20):\n",
    "        train_loader, val_loader = self.get_dataloaders()\n",
    "        print('staring training ********')\n",
    "        last_loss = 0\n",
    "        for epoch in range(start_epoch, nb_epochs):\n",
    "            self.net.train()\n",
    "            running_loss = 0\n",
    "\n",
    "            for step, batch in enumerate(train_loader, 0):\n",
    "                x, y = batch\n",
    "                x = Variable(x).cuda()\n",
    "                y = Variable(y.float()).cuda()\n",
    "                predictions = self.net(x)\n",
    "\n",
    "                loss = self.loss_function(predictions, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                if step % print_after == 0:\n",
    "                    print('epoch: {} | step: {} | loss: {}'.format(epoch, step, loss.item()))\n",
    "\n",
    "            self.running_loss_train.append(running_loss/step)\n",
    "            print('avg training loss: {:.5f}'.format(running_loss/step))\n",
    "            running_loss = 0\n",
    "\n",
    "            self.net.eval()\n",
    "            print(\"----------------------------------------------------validating------------------------------------------------\")\n",
    "            for step, batch in enumerate(val_loader, 0):\n",
    "                \n",
    "                x, y = batch\n",
    "                x = Variable(x).cuda()\n",
    "                y = Variable(y.float()).cuda()\n",
    "                predictions = self.net(x)\n",
    "                loss = self.loss_function(predictions, y)\n",
    "                running_loss += loss.item()\n",
    "                if step % print_after == 0:\n",
    "                    print('epoch: {} | step: {} | loss: {}'.format(epoch, step, loss.item()))\n",
    "\n",
    "            self.running_loss_val.append(running_loss/step)\n",
    "            print('avg val loss: {:.5f}'.format(running_loss/step))\n",
    "\n",
    "            self.save_loss_img()\n",
    "            if last_loss == 0 or running_loss < last_loss:\n",
    "                T.save(self.net, self.save_dir + f'model_best.pth')\n",
    "                last_loss = running_loss\n",
    "\n",
    "        T.save(self.net, self.save_dir + f'model_{epoch}.pth')\n",
    "\n",
    "    def get_loss(self):\n",
    "        return [self.running_loss_train, self.running_loss_val]\n",
    "\n",
    "    def plot_loss(self):\n",
    "        train_loss = pd.DataFrame(self.get_loss()).transpose()\n",
    "        train_loss.plot()\n",
    "        plt.show()\n",
    "\n",
    "    def save_loss_img(self):\n",
    "        train_loss = pd.DataFrame(self.get_loss()).transpose()\n",
    "        train_loss.plot()\n",
    "        plt.savefig('train_loss.png')\n",
    "\n",
    "    def get_dataloaders(self):\n",
    "        train_stairdata,val_stairdata = self.create_stairdata()\n",
    "        train_loader = DataLoader(train_stairdata, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(sval_stairdata, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
    "        print('DataLoader returned')\n",
    "        return (train_loader, val_loader)\n",
    "\n",
    "    def create_stairdata(self):\n",
    "        return stairdata(self.train_folder, self.get_transforms()), stairdata(self.val_folder, self.get_transforms())\n",
    "\n",
    "    def get_transforms(self):\n",
    "        return transforms.Compose(transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "\n",
    "    def get_accuracy(self, predictions, targets):\n",
    "        predictions = predictions.argmax(dim=1)\n",
    "        accuracy = sum(predictions == target) * 100 / len(predictions)\n",
    "        self.accuracy.append(accuracy)\n",
    "        return accuracy\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.lyr1 = nn.Sequential(nn.Conv2d(3, 36, kernel_size = 5, stride = 2), nn.BatchNorm2d(36), nn.ELU())\n",
    "        self.lyr2 = nn.Sequential(nn.Conv2d(36, 48, kernel_size = 5, stride = 2), nn.BatchNorm2d(48), nn.ELU())\n",
    "        self.lyr3 = nn.Sequential(nn.Conv2d(48, 64, kernel_size = 5, stride = 2), nn.BatchNorm2d(64), nn.ELU())\n",
    "        self.lyr4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size = 3), nn.BatchNorm2d(64), nn.ELU())\n",
    "        self.lyr5 = nn.Sequential(nn.Conv2d(64, 64, kernel_size = 3), nn.BatchNorm2d(64), nn.ELU())\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(64*73*53, 100), nn.ELU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(100, 50), nn.ELU())\n",
    "        self.fc3 = nn.Sequential(nn.Linear(50, 10), nn.ELU())\n",
    "        self.fc4 = nn.Linear(10, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.lyr1(x)\n",
    "        out = self.lyr2(out)\n",
    "        out = self.lyr3(out)\n",
    "        out = self.lyr4(out)\n",
    "        out = self.lyr5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "    \n",
    "model = CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'data/cloning/'\n",
    "val_folder = ''\n",
    "batch_size = \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "nb_epochs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stairnet_trainer = trainer(model, loss_function, train_folder, val_folder, batch_size=batch_size)\n",
    "stairnet_trainer.fit(args.nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(38)\n",
    "\n",
    "def split_train_val(path, pct=0.9):\n",
    "    os.mkdir(path +'/train', exist_ok=True)\n",
    "    os.mkdir(path +'/val', exist_ok=True)\n",
    "    lst = list(np.random.shuffle(os.listdir(path)))\n",
    "    lst_train, lst_val= lst[:int(len(lst)*pct)], lst[int(len(lst)*pct):]\n",
    "    for i in lst_train:\n",
    "        os.rename(f'{path}/{i}', f'{path}/train/{i}')\n",
    "    for i in lst_val:\n",
    "        os.rename(f'{path}/{i}', f'{path}/val/{i}')\n",
    "    print('done!')\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
